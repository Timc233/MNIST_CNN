{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LeNet-5 architecture\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.Sigmoid(),\n",
    "            nn.LazyLinear(84), nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1571b62f0>\n"
     ]
    }
   ],
   "source": [
    "print(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 10.83\n",
      "Epoch 2: Loss = 10.80\n",
      "Epoch 3: Loss = 10.80\n",
      "Epoch 4: Loss = 10.80\n",
      "Epoch 5: Loss = 10.80\n",
      "Epoch 6: Loss = 10.80\n",
      "Epoch 7: Loss = 10.80\n",
      "Epoch 8: Loss = 10.79\n",
      "Epoch 9: Loss = 9.95\n",
      "Epoch 10: Loss = 4.49\n",
      "Epoch 11: Loss = 1.43\n",
      "Epoch 12: Loss = 0.85\n",
      "Epoch 13: Loss = 0.63\n",
      "Epoch 14: Loss = 0.51\n",
      "Epoch 15: Loss = 0.43\n",
      "Epoch 16: Loss = 0.38\n",
      "Epoch 17: Loss = 0.34\n",
      "Epoch 18: Loss = 0.31\n",
      "Epoch 19: Loss = 0.28\n",
      "Epoch 20: Loss = 0.26\n",
      "Epoch 21: Loss = 0.24\n",
      "Epoch 22: Loss = 0.23\n",
      "Epoch 23: Loss = 0.22\n",
      "Epoch 24: Loss = 0.21\n",
      "Epoch 25: Loss = 0.20\n",
      "Epoch 26: Loss = 0.19\n",
      "Epoch 27: Loss = 0.17\n",
      "Epoch 28: Loss = 0.16\n",
      "Epoch 29: Loss = 0.16\n",
      "Epoch 30: Loss = 0.16\n",
      "Epoch 31: Loss = 0.14\n",
      "Epoch 32: Loss = 0.14\n",
      "Epoch 33: Loss = 0.13\n",
      "Epoch 34: Loss = 0.13\n",
      "Epoch 35: Loss = 0.13\n",
      "Epoch 36: Loss = 0.13\n",
      "Epoch 37: Loss = 0.12\n",
      "Epoch 38: Loss = 0.11\n",
      "Epoch 39: Loss = 0.10\n",
      "Epoch 40: Loss = 0.10\n",
      "Epoch 41: Loss = 0.09\n",
      "Epoch 42: Loss = 0.09\n",
      "Epoch 43: Loss = 0.09\n",
      "Epoch 44: Loss = 0.09\n",
      "Epoch 45: Loss = 0.08\n",
      "Epoch 46: Loss = 0.08\n",
      "Epoch 47: Loss = 0.08\n",
      "Epoch 48: Loss = 0.08\n",
      "Epoch 49: Loss = 0.07\n",
      "Epoch 50: Loss = 0.07\n",
      "Epoch 51: Loss = 0.07\n",
      "Epoch 52: Loss = 0.06\n",
      "Epoch 53: Loss = 0.07\n",
      "Epoch 54: Loss = 0.06\n",
      "Epoch 55: Loss = 0.06\n",
      "Epoch 56: Loss = 0.05\n",
      "Epoch 57: Loss = 0.05\n",
      "Epoch 58: Loss = 0.05\n",
      "Epoch 59: Loss = 0.05\n",
      "Epoch 60: Loss = 0.05\n",
      "Epoch 61: Loss = 0.04\n",
      "Epoch 62: Loss = 0.04\n",
      "Epoch 63: Loss = 0.04\n",
      "Epoch 64: Loss = 0.04\n",
      "Epoch 65: Loss = 0.04\n",
      "Epoch 66: Loss = 0.04\n",
      "Epoch 67: Loss = 0.04\n",
      "Epoch 68: Loss = 0.04\n",
      "Epoch 69: Loss = 0.03\n",
      "Epoch 70: Loss = 0.03\n",
      "Epoch 71: Loss = 0.03\n",
      "Epoch 72: Loss = 0.03\n",
      "Epoch 73: Loss = 0.03\n",
      "Epoch 74: Loss = 0.03\n",
      "Epoch 75: Loss = 0.02\n",
      "Epoch 76: Loss = 0.02\n",
      "Epoch 77: Loss = 0.02\n",
      "Epoch 78: Loss = 0.02\n",
      "Epoch 79: Loss = 0.02\n",
      "Epoch 80: Loss = 0.02\n",
      "Epoch 81: Loss = 0.02\n",
      "Epoch 82: Loss = 0.02\n",
      "Epoch 83: Loss = 0.02\n",
      "Epoch 84: Loss = 0.02\n",
      "Epoch 85: Loss = 0.02\n",
      "Epoch 86: Loss = 0.02\n",
      "Epoch 87: Loss = 0.01\n",
      "Epoch 88: Loss = 0.01\n",
      "Epoch 89: Loss = 0.01\n",
      "Epoch 90: Loss = 0.01\n",
      "Epoch 91: Loss = 0.01\n",
      "Epoch 92: Loss = 0.01\n",
      "Epoch 93: Loss = 0.01\n",
      "Epoch 94: Loss = 0.01\n",
      "Epoch 95: Loss = 0.01\n",
      "Epoch 96: Loss = 0.01\n",
      "Epoch 97: Loss = 0.01\n",
      "Epoch 98: Loss = 0.01\n",
      "Epoch 99: Loss = 0.01\n",
      "Epoch 100: Loss = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "model = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum =0.9)\n",
    "Epochs = 100\n",
    "\n",
    "for epoch in range(0,Epochs):\n",
    "    model.train()\n",
    "    train_iter = iter(train_loader)\n",
    "    loss_acc = 0\n",
    "\n",
    "    for idx, (images, labels) in enumerate(train_iter):\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss_acc += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    loss_acc /= Epochs\n",
    "    print('Epoch %d: Loss = %.2f'%(epoch+1, loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n",
      "accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "test_epochs = 25\n",
    "model.eval()\n",
    "for epoch in range(test_epochs):\n",
    "    acc_cum = 0\n",
    "    test_size = 0\n",
    "\n",
    "    for idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images.float()).detach()\n",
    "        output =torch.argmax(output, dim=-1)\n",
    "        current_correct_num = output == labels\n",
    "        acc_cum += np.sum(current_correct_num.to('cpu').numpy(), axis=-1)\n",
    "        test_size += current_correct_num.shape[0]\n",
    "    acc = acc_cum / test_size\n",
    "    print('accuracy: %.3f'%(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a953712b2f5ca21a7f107b54c791af98f8b5ece783e653148ecddf822e655a87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
